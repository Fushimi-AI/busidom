# Feature 3.1: pgvector Setup

## Metadata
| Field | Value |
|-------|-------|
| **Feature ID** | 3.1 |
| **Phase** | 3 - Intelligence |
| **Priority** | Critical |
| **Estimated Effort** | 4-5 hours |
| **Dependencies** | 2.1 (PostgreSQL Setup) |
| **Approval** | [ ] |
| **Status** | Not Started |

---

## Overview

Set up pgvector extension for PostgreSQL to enable vector storage and similarity search, forming the foundation for semantic memory retrieval.

## User Story

As a **system**, I need **vector storage capabilities** so that **I can find semantically similar content**.

---

## Requirements

### Functional Requirements
1. Install pgvector extension
2. Create embeddings table
3. Vector similarity search (cosine)
4. Index for fast retrieval
5. Batch insert support

### Non-Functional Requirements
- Similarity search < 100ms for 100K vectors
- Support 1536-dimension vectors (OpenAI)
- HNSW index for speed
- Handle null embeddings gracefully

---

## Technical Specification

### Migration

```sql
-- migrations/003_pgvector.sql

-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Embeddings table
CREATE TABLE embeddings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_type VARCHAR(50) NOT NULL,  -- 'message', 'context', 'document'
  source_id UUID NOT NULL,
  content TEXT NOT NULL,
  embedding vector(1536),  -- OpenAI dimension
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- HNSW index for fast similarity search
CREATE INDEX embeddings_embedding_idx ON embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Index for source lookups
CREATE INDEX embeddings_source_idx ON embeddings(source_type, source_id);

-- Function for similarity search
CREATE OR REPLACE FUNCTION search_similar(
  query_embedding vector(1536),
  match_count INT DEFAULT 10,
  similarity_threshold FLOAT DEFAULT 0.7
)
RETURNS TABLE (
  id UUID,
  source_type VARCHAR(50),
  source_id UUID,
  content TEXT,
  similarity FLOAT
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    e.id,
    e.source_type,
    e.source_id,
    e.content,
    1 - (e.embedding <=> query_embedding) AS similarity
  FROM embeddings e
  WHERE e.embedding IS NOT NULL
    AND 1 - (e.embedding <=> query_embedding) > similarity_threshold
  ORDER BY e.embedding <=> query_embedding
  LIMIT match_count;
END;
$$ LANGUAGE plpgsql;
```

### Vector Repository

```typescript
// src/infrastructure/repositories/embedding.repository.ts
import { DatabaseClient } from '../database/client';

export interface Embedding {
  id: string;
  sourceType: 'message' | 'context' | 'document';
  sourceId: string;
  content: string;
  embedding: number[] | null;
  metadata: Record<string, unknown>;
  createdAt: Date;
}

export interface SimilarityResult {
  id: string;
  sourceType: string;
  sourceId: string;
  content: string;
  similarity: number;
}

export class EmbeddingRepository {
  constructor(private db: DatabaseClient) {}

  async insert(data: {
    sourceType: string;
    sourceId: string;
    content: string;
    embedding: number[];
    metadata?: Record<string, unknown>;
  }): Promise<Embedding> {
    const result = await this.db.queryOne<any>(
      `INSERT INTO embeddings (source_type, source_id, content, embedding, metadata)
       VALUES ($1, $2, $3, $4, $5)
       RETURNING *`,
      [
        data.sourceType,
        data.sourceId,
        data.content,
        `[${data.embedding.join(',')}]`,
        data.metadata || {},
      ]
    );

    return this.toEmbedding(result);
  }

  async insertBatch(items: Array<{
    sourceType: string;
    sourceId: string;
    content: string;
    embedding: number[];
  }>): Promise<number> {
    if (items.length === 0) return 0;

    const values = items.map((item, i) => {
      const offset = i * 4;
      return `($${offset + 1}, $${offset + 2}, $${offset + 3}, $${offset + 4})`;
    }).join(', ');

    const params = items.flatMap(item => [
      item.sourceType,
      item.sourceId,
      item.content,
      `[${item.embedding.join(',')}]`,
    ]);

    const result = await this.db.execute(
      `INSERT INTO embeddings (source_type, source_id, content, embedding)
       VALUES ${values}`,
      params
    );

    return result;
  }

  async searchSimilar(
    queryEmbedding: number[],
    options: {
      limit?: number;
      threshold?: number;
      sourceType?: string;
    } = {}
  ): Promise<SimilarityResult[]> {
    const { limit = 10, threshold = 0.7, sourceType } = options;

    let sql = `
      SELECT
        id,
        source_type,
        source_id,
        content,
        1 - (embedding <=> $1) AS similarity
      FROM embeddings
      WHERE embedding IS NOT NULL
        AND 1 - (embedding <=> $1) > $2
    `;
    const params: unknown[] = [`[${queryEmbedding.join(',')}]`, threshold];

    if (sourceType) {
      sql += ` AND source_type = $3`;
      params.push(sourceType);
    }

    sql += ` ORDER BY embedding <=> $1 LIMIT $${params.length + 1}`;
    params.push(limit);

    const rows = await this.db.query<any>(sql, params);

    return rows.map(row => ({
      id: row.id,
      sourceType: row.source_type,
      sourceId: row.source_id,
      content: row.content,
      similarity: parseFloat(row.similarity),
    }));
  }

  async findBySourceId(sourceId: string): Promise<Embedding | null> {
    const row = await this.db.queryOne<any>(
      `SELECT * FROM embeddings WHERE source_id = $1`,
      [sourceId]
    );

    return row ? this.toEmbedding(row) : null;
  }

  async deleteBySourceId(sourceId: string): Promise<boolean> {
    const count = await this.db.execute(
      `DELETE FROM embeddings WHERE source_id = $1`,
      [sourceId]
    );
    return count > 0;
  }

  async count(): Promise<number> {
    const result = await this.db.queryOne<{ count: string }>(
      `SELECT COUNT(*) FROM embeddings`
    );
    return parseInt(result?.count || '0');
  }

  private toEmbedding(row: any): Embedding {
    return {
      id: row.id,
      sourceType: row.source_type,
      sourceId: row.source_id,
      content: row.content,
      embedding: row.embedding,
      metadata: row.metadata,
      createdAt: row.created_at,
    };
  }
}
```

### Vector Service

```typescript
// src/core/vector/vector.service.ts
import { EmbeddingRepository, SimilarityResult } from '../../infrastructure/repositories/embedding.repository';

export class VectorService {
  constructor(private embeddingRepo: EmbeddingRepository) {}

  async store(
    sourceType: 'message' | 'context' | 'document',
    sourceId: string,
    content: string,
    embedding: number[]
  ): Promise<void> {
    // Check if already exists
    const existing = await this.embeddingRepo.findBySourceId(sourceId);

    if (existing) {
      await this.embeddingRepo.deleteBySourceId(sourceId);
    }

    await this.embeddingRepo.insert({
      sourceType,
      sourceId,
      content,
      embedding,
    });
  }

  async search(
    queryEmbedding: number[],
    options?: {
      limit?: number;
      threshold?: number;
      sourceType?: 'message' | 'context' | 'document';
    }
  ): Promise<SimilarityResult[]> {
    return this.embeddingRepo.searchSimilar(queryEmbedding, options);
  }

  async storeBatch(
    items: Array<{
      sourceType: 'message' | 'context' | 'document';
      sourceId: string;
      content: string;
      embedding: number[];
    }>
  ): Promise<number> {
    return this.embeddingRepo.insertBatch(items);
  }

  async getStats(): Promise<{ count: number }> {
    const count = await this.embeddingRepo.count();
    return { count };
  }
}
```

---

## Tasks Breakdown

| Task | Description | Estimate |
|------|-------------|----------|
| 3.1.1 | Install pgvector on PostgreSQL | 30 min |
| 3.1.2 | Create migration with extension | 20 min |
| 3.1.3 | Create embeddings table | 20 min |
| 3.1.4 | Add HNSW index | 20 min |
| 3.1.5 | Implement EmbeddingRepository | 45 min |
| 3.1.6 | Add similarity search | 30 min |
| 3.1.7 | Implement batch insert | 30 min |
| 3.1.8 | Create VectorService | 30 min |
| 3.1.9 | Write integration tests | 45 min |
| 3.1.10 | Benchmark search performance | 20 min |

---

## Acceptance Criteria

- [ ] pgvector extension installed
- [ ] Embeddings table created
- [ ] Vector insert works
- [ ] Similarity search works
- [ ] HNSW index active
- [ ] Search < 100ms for 10K vectors
- [ ] Batch insert works
- [ ] Null embeddings handled

---

## Dependencies

```bash
# PostgreSQL with pgvector
# Docker: ankane/pgvector
# Or install: CREATE EXTENSION vector;
```

---

## Definition of Done

- [ ] All tasks completed
- [ ] All acceptance criteria met
- [ ] Performance benchmarks passed
- [ ] Integration tests passing

