# Feature 2.1: PostgreSQL Setup

## Metadata
| Field | Value |
|-------|-------|
| **Feature ID** | 2.1 |
| **Phase** | 2 - Persistence |
| **Priority** | Critical |
| **Estimated Effort** | 4-6 hours |
| **Dependencies** | 0.3 (Core Architecture), 0.5 (Configuration) |
| **Approval** | [ ] |
| **Status** | Not Started |

---

## Overview

Set up PostgreSQL database infrastructure including connection management, migrations, and base repository patterns for all persistent data storage.

## User Story

As a **developer**, I want a **robust database layer** so that **user data persists reliably beyond JSON files**.

---

## Requirements

### Functional Requirements
1. PostgreSQL connection pooling
2. Migration system for schema changes
3. Base repository pattern
4. Transaction support
5. Connection health checks
6. Graceful connection shutdown

### Non-Functional Requirements
- Connection pool: 5-20 connections
- Query timeout: 30 seconds
- Automatic reconnection
- SSL in production

---

## Technical Specification

### Database Schema (Initial)

```sql
-- migrations/001_initial.sql

-- Users table
CREATE TABLE users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  email VARCHAR(255) UNIQUE NOT NULL,
  password_hash VARCHAR(255) NOT NULL,
  name VARCHAR(255),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Businesses table
CREATE TABLE businesses (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  name VARCHAR(255) NOT NULL,
  industry VARCHAR(100),
  stage VARCHAR(50) DEFAULT 'idea',
  context JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Conversations table
CREATE TABLE conversations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  business_id UUID REFERENCES businesses(id) ON DELETE CASCADE,
  title VARCHAR(255),
  message_count INTEGER DEFAULT 0,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Messages table
CREATE TABLE messages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  conversation_id UUID REFERENCES conversations(id) ON DELETE CASCADE,
  role VARCHAR(20) NOT NULL,
  content TEXT NOT NULL,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_businesses_user_id ON businesses(user_id);
CREATE INDEX idx_conversations_business_id ON conversations(business_id);
CREATE INDEX idx_messages_conversation_id ON messages(conversation_id);
CREATE INDEX idx_messages_created_at ON messages(created_at);

-- Updated at trigger
CREATE OR REPLACE FUNCTION update_updated_at()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER users_updated_at
  BEFORE UPDATE ON users
  FOR EACH ROW EXECUTE FUNCTION update_updated_at();

CREATE TRIGGER businesses_updated_at
  BEFORE UPDATE ON businesses
  FOR EACH ROW EXECUTE FUNCTION update_updated_at();

CREATE TRIGGER conversations_updated_at
  BEFORE UPDATE ON conversations
  FOR EACH ROW EXECUTE FUNCTION update_updated_at();
```

### Database Client

```typescript
// src/infrastructure/database/client.ts
import { Pool, PoolClient } from 'pg';
import { Config } from '../../config';

export class DatabaseClient {
  private pool: Pool;
  private isConnected: boolean = false;

  constructor(config: Config['database']) {
    this.pool = new Pool({
      connectionString: config.url,
      max: config.poolSize || 10,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 5000,
      ssl: config.ssl ? { rejectUnauthorized: false } : undefined,
    });

    this.pool.on('error', (err) => {
      console.error('Unexpected database error:', err);
    });
  }

  async connect(): Promise<void> {
    const client = await this.pool.connect();
    client.release();
    this.isConnected = true;
  }

  async disconnect(): Promise<void> {
    await this.pool.end();
    this.isConnected = false;
  }

  async query<T>(sql: string, params?: unknown[]): Promise<T[]> {
    const result = await this.pool.query(sql, params);
    return result.rows;
  }

  async queryOne<T>(sql: string, params?: unknown[]): Promise<T | null> {
    const rows = await this.query<T>(sql, params);
    return rows[0] || null;
  }

  async execute(sql: string, params?: unknown[]): Promise<number> {
    const result = await this.pool.query(sql, params);
    return result.rowCount || 0;
  }

  async transaction<T>(fn: (client: PoolClient) => Promise<T>): Promise<T> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');
      const result = await fn(client);
      await client.query('COMMIT');
      return result;
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  async healthCheck(): Promise<boolean> {
    try {
      await this.pool.query('SELECT 1');
      return true;
    } catch {
      return false;
    }
  }
}
```

### Migration Runner

```typescript
// src/infrastructure/database/migrator.ts
import * as fs from 'fs/promises';
import * as path from 'path';
import { DatabaseClient } from './client';

interface Migration {
  id: number;
  name: string;
  sql: string;
}

export class Migrator {
  constructor(
    private db: DatabaseClient,
    private migrationsPath: string
  ) {}

  async run(): Promise<void> {
    await this.ensureMigrationTable();

    const applied = await this.getAppliedMigrations();
    const pending = await this.getPendingMigrations(applied);

    for (const migration of pending) {
      console.log(`Running migration: ${migration.name}`);
      await this.applyMigration(migration);
    }

    console.log(`Migrations complete. Applied ${pending.length} migrations.`);
  }

  private async ensureMigrationTable(): Promise<void> {
    await this.db.execute(`
      CREATE TABLE IF NOT EXISTS migrations (
        id SERIAL PRIMARY KEY,
        name VARCHAR(255) NOT NULL,
        applied_at TIMESTAMP DEFAULT NOW()
      )
    `);
  }

  private async getAppliedMigrations(): Promise<string[]> {
    const rows = await this.db.query<{ name: string }>('SELECT name FROM migrations');
    return rows.map(r => r.name);
  }

  private async getPendingMigrations(applied: string[]): Promise<Migration[]> {
    const files = await fs.readdir(this.migrationsPath);
    const migrations: Migration[] = [];

    for (const file of files.sort()) {
      if (!file.endsWith('.sql')) continue;
      if (applied.includes(file)) continue;

      const sql = await fs.readFile(
        path.join(this.migrationsPath, file),
        'utf-8'
      );

      migrations.push({
        id: parseInt(file.split('_')[0]),
        name: file,
        sql,
      });
    }

    return migrations;
  }

  private async applyMigration(migration: Migration): Promise<void> {
    await this.db.transaction(async (client) => {
      await client.query(migration.sql);
      await client.query(
        'INSERT INTO migrations (name) VALUES ($1)',
        [migration.name]
      );
    });
  }
}
```

### Base Repository

```typescript
// src/infrastructure/database/base.repository.ts
import { DatabaseClient } from './client';

export abstract class BaseRepository<T> {
  constructor(
    protected db: DatabaseClient,
    protected tableName: string
  ) {}

  async findById(id: string): Promise<T | null> {
    return this.db.queryOne<T>(
      `SELECT * FROM ${this.tableName} WHERE id = $1`,
      [id]
    );
  }

  async findAll(limit: number = 100, offset: number = 0): Promise<T[]> {
    return this.db.query<T>(
      `SELECT * FROM ${this.tableName} ORDER BY created_at DESC LIMIT $1 OFFSET $2`,
      [limit, offset]
    );
  }

  async delete(id: string): Promise<boolean> {
    const count = await this.db.execute(
      `DELETE FROM ${this.tableName} WHERE id = $1`,
      [id]
    );
    return count > 0;
  }

  protected async insert(data: Partial<T>): Promise<T> {
    const keys = Object.keys(data);
    const values = Object.values(data);
    const placeholders = keys.map((_, i) => `$${i + 1}`).join(', ');

    const sql = `
      INSERT INTO ${this.tableName} (${keys.join(', ')})
      VALUES (${placeholders})
      RETURNING *
    `;

    const result = await this.db.queryOne<T>(sql, values);
    return result!;
  }

  protected async update(id: string, data: Partial<T>): Promise<T | null> {
    const keys = Object.keys(data);
    const values = Object.values(data);
    const sets = keys.map((k, i) => `${k} = $${i + 2}`).join(', ');

    const sql = `
      UPDATE ${this.tableName}
      SET ${sets}
      WHERE id = $1
      RETURNING *
    `;

    return this.db.queryOne<T>(sql, [id, ...values]);
  }
}
```

---

## Tasks Breakdown

| Task | Description | Estimate |
|------|-------------|----------|
| 2.1.1 | Add pg dependency | 10 min |
| 2.1.2 | Create DatabaseClient class | 45 min |
| 2.1.3 | Implement connection pooling | 30 min |
| 2.1.4 | Add transaction support | 30 min |
| 2.1.5 | Create migration runner | 45 min |
| 2.1.6 | Write initial migration (schema) | 45 min |
| 2.1.7 | Create BaseRepository | 30 min |
| 2.1.8 | Add health check endpoint | 15 min |
| 2.1.9 | Configure for local/prod | 20 min |
| 2.1.10 | Write integration tests | 45 min |

---

## Acceptance Criteria

- [ ] Database connects successfully
- [ ] Connection pooling works
- [ ] Migrations run automatically
- [ ] Transactions commit/rollback properly
- [ ] Health check returns status
- [ ] Graceful shutdown closes connections
- [ ] Works with local PostgreSQL
- [ ] SSL works in production mode

---

## Dependencies (npm)

```json
{
  "dependencies": {
    "pg": "^8.11.0"
  },
  "devDependencies": {
    "@types/pg": "^8.10.0"
  }
}
```

---

## File Structure

```
src/
├── infrastructure/
│   └── database/
│       ├── index.ts
│       ├── client.ts
│       ├── migrator.ts
│       └── base.repository.ts
migrations/
└── 001_initial.sql
```

---

## Environment Variables

```env
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/business_os
DATABASE_POOL_SIZE=10
DATABASE_SSL=false
```

---

## Definition of Done

- [ ] All tasks completed
- [ ] All acceptance criteria met
- [ ] Migrations tested
- [ ] Integration tests passing
- [ ] Documentation updated

